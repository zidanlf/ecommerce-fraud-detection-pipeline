version: '3.8'

# --- COMMON AIRFLOW SERVICE DEFINITION ---
x-airflow-common: &airflow-common
  build: .
  env_file:
    - .env
  environment:
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
    - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
    - AIRFLOW__CORE__LOAD_EXAMPLES=false
    - AIRFLOW_CONN_POSTGRES_DEFAULT=postgresql://airflow:airflow@postgres-project:5432/final_project_db
    - PYTHONPATH=/opt/airflow
    - GOOGLE_APPLICATION_CREDENTIALS=/opt/airflow/keys/gcp_key.json
    - AIRFLOW__WEBSERVER__SECRET_KEY=123456789
  volumes:
    - ./dags:/opt/airflow/dags
    - ./scripts:/opt/airflow/scripts
    - ./streaming:/opt/airflow/streaming
    - ./keys:/opt/airflow/keys
    - ./fraud_analytics:/opt/airflow/fraud_analytics
  depends_on:
    postgres-airflow:
      condition: service_healthy
    postgres-project:
      condition: service_healthy

# --- SERVICES DEFINITION ---
services:
  postgres-project:
    image: postgres:15
    container_name: postgres_project
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: final_project_db
    ports:
      - "5432:5432"
    volumes:
      - postgres-project-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always

  # --- AIRFLOW POSTGRESQL DATABASE ---
  postgres-airflow:
    image: postgres:15
    container_name: postgres_airflow
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5434:5432"
    volumes:
      - postgres-airflow-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always

  # --- KAFKA SERVICES ---
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"

  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: kafka 
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "orders:1:1"
    depends_on:
      - zookeeper

  # --- AIRFLOW SERVICES ---
  airflow-webserver:
    <<: *airflow-common
    container_name: airflow_webserver
    hostname: airflow-webserver
    command: webserver
    ports:
      - "8080:8080"
    restart: always
    depends_on:
      postgres-airflow:
        condition: service_healthy
      postgres-project:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow_scheduler
    hostname: airflow-scheduler
    command: scheduler
    restart: always
    depends_on:
      postgres-airflow:
        condition: service_healthy
      postgres-project:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully

  airflow-init:
    <<: *airflow-common
    container_name: airflow_init
    command: >
      bash -c "airflow db init &&
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com"
    depends_on:
      postgres-airflow:
        condition: service_healthy

# --- METABASE (BI TOOL) ---
  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    ports:
      - "3000:3000"
    environment:
      - MB_DB_FILE=/metabase-data/metabase.db
    volumes:
      - metabase-data:/metabase-data
      - ./keys:/app/keys
    networks:
      - default
    restart: always

volumes:
  postgres-project-data:
  postgres-airflow-data:
  metabase-data: